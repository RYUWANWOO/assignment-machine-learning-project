{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_08_solution_latest.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rgD-FF4MA9Kg",
        "SnBT9fWXA9Kj"
      ],
      "machine_shape": "hm"
    },
    "interpreter": {
      "hash": "84bbda367bac7e7bffd9b7890a44d65326aaedad40e5a9021c2651157391b1ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9d855fc37aed4d9b8288aeb8c4e6ddf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdf7c3e5de3e472dabec7beaa9b501e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2276171da6824033ad40a3c6c1ff544b",
              "IPY_MODEL_d0bd2712e3d04115a402cb8e2a2c5cbc",
              "IPY_MODEL_21085e2337114646875c594174cc437e"
            ]
          }
        },
        "cdf7c3e5de3e472dabec7beaa9b501e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2276171da6824033ad40a3c6c1ff544b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_579b5194bec746839ad337f55e27e70c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d46aacc34f145f78b7e23349dfea97f"
          }
        },
        "d0bd2712e3d04115a402cb8e2a2c5cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51e4281c2e53430695824cfdc6a2d6de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2a76c73b768424e91915637d6128e37"
          }
        },
        "21085e2337114646875c594174cc437e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_05b264e8472d41d584153d03c5493663",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/1000 [00:04&lt;15:16,  1.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bd67f34f73d4b6c8fb90c8149cae494"
          }
        },
        "579b5194bec746839ad337f55e27e70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d46aacc34f145f78b7e23349dfea97f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51e4281c2e53430695824cfdc6a2d6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2a76c73b768424e91915637d6128e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05b264e8472d41d584153d03c5493663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bd67f34f73d4b6c8fb90c8149cae494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQGQXmOpA9J-"
      },
      "source": [
        "# Unsupervised image denoising"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiKuXIvrYCNj"
      },
      "source": [
        "## Connect Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK5OQ94EXkHs",
        "outputId": "b15e9d00-658f-431f-9c11-fc81ad7be694"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGBcGR2LA9KI"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNpI2DZ6A9KJ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from torchvision.transforms import Compose, ToTensor, ToPILImage, Resize, Lambda, Normalize, Grayscale\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from math import log10\n",
        "from tqdm.notebook import tqdm\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU32jTFuA9KM"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf-s-8nrA9KN",
        "outputId": "0bd71a82-6a3b-4773-e77d-c8d9d8c014ed"
      },
      "source": [
        "directory_data  = 'drive/MyDrive'\n",
        "filename_data   = 'assignment_08_data.npz'\n",
        "data            = np.load(os.path.join(directory_data, filename_data))\n",
        "\n",
        "\n",
        "original_train = data['original_train'] \n",
        "noise_train    = data['noise_train']\n",
        "\n",
        "original_test = data['original_test'] \n",
        "noise_test    = data['noise_test']\n",
        "\n",
        "print('*************************************************')\n",
        "print('size of noise_train    : ', noise_train.shape)\n",
        "print('*************************************************')\n",
        "print('size of noise_test    : ', noise_test.shape)\n",
        "print('*************************************************')\n",
        "print('number of training image :', noise_train.shape[0])\n",
        "print('height of training image :', noise_train.shape[1])\n",
        "print('width of training image  :', noise_train.shape[2])\n",
        "print('*************************************************')\n",
        "print('number of testing image :', noise_test.shape[0])\n",
        "print('height of testing image :', noise_test.shape[1])\n",
        "print('width of testing image  :', noise_test.shape[2])\n",
        "print('*************************************************')\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "size of noise_train    :  (2000, 64, 64)\n",
            "*************************************************\n",
            "size of noise_test    :  (900, 64, 64)\n",
            "*************************************************\n",
            "number of training image : 2000\n",
            "height of training image : 64\n",
            "width of training image  : 64\n",
            "*************************************************\n",
            "number of testing image : 900\n",
            "height of testing image : 64\n",
            "width of testing image  : 64\n",
            "*************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20TiZsA_A9KO"
      },
      "source": [
        "## Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtDynD4nA9KP"
      },
      "source": [
        "device        = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ==================================================\n",
        "# determine optimal hyper-parameters to obtain best testing performance\n",
        "number_epoch    = 1000\n",
        "size_minibatch  = 50\n",
        "learning_rate   = 0.1\n",
        "momentum        = 0.9\n",
        "weight_decay    = 0.0001\n",
        "weight_total_variation = 0.001\n",
        "# =================================================="
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AbHCZPpA9KR"
      },
      "source": [
        "## Costumize dataloader for pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UveCjrBA9KS"
      },
      "source": [
        "class dataset (Dataset):\n",
        "  def  __init__(self, original,noise):\n",
        "\n",
        "    self.original = original\n",
        "    self.noise    = noise\n",
        "        \n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    original    = self.original[index]\n",
        "    noise       = self.noise[index]\n",
        "    \n",
        "    original   = torch.FloatTensor(original).unsqueeze(dim=0)\n",
        "    noise      = torch.FloatTensor(noise).unsqueeze(dim=0)\n",
        "\n",
        "\n",
        "    return (original , noise)\n",
        "  \n",
        "  def __len__(self):\n",
        "\n",
        "     return self.original.shape[0]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "357alwWgA9KU"
      },
      "source": [
        "## Construct datasets and dataloaders for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7JDqjSVA9KU"
      },
      "source": [
        "dataset_train = dataset(original_train, noise_train) \n",
        "dataset_test  = dataset(original_test, noise_test) \n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=size_minibatch, shuffle=True, drop_last=True, num_workers=2)\n",
        "dataloader_test  = DataLoader(dataset_test,  batch_size=size_minibatch, shuffle=False, drop_last=True, num_workers=2) "
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DQ3_o-VA9KV"
      },
      "source": [
        "## Shape of the data with data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCNL_T-HA9KW",
        "outputId": "0411f337-d41e-40e4-edec-67e4a7e68543"
      },
      "source": [
        "(original_train, noise_train)   = dataset_train[0]\n",
        "(original_test, noise_test)     = dataset_test[0]\n",
        "\n",
        "print('************************************************************')\n",
        "print('shape of the original image in the training dataset:', original_train.shape)\n",
        "print('shape of the noisy image in the training dataset:', noise_train.shape)\n",
        "print('************************************************************')\n",
        "print('shape of the original image in the testing dataset:', original_test.shape)\n",
        "print('shape of the noisy image in the testing dataset:', noise_test.shape)\n",
        "print('************************************************************')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************************************************\n",
            "shape of the original image in the training dataset: torch.Size([1, 64, 64])\n",
            "shape of the noisy image in the training dataset: torch.Size([1, 64, 64])\n",
            "************************************************************\n",
            "shape of the original image in the testing dataset: torch.Size([1, 64, 64])\n",
            "shape of the noisy image in the testing dataset: torch.Size([1, 64, 64])\n",
            "************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yn9jMLrA9KX"
      },
      "source": [
        "## Class for the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esyw9M--A9KY"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network,self).__init__()\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # Encoder\n",
        "        # -------------------------------------------------\n",
        "        self.e_layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),  \n",
        "                        nn.MaxPool2d(2,2),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(16),\n",
        "        )\n",
        "        self.e_layer2 = nn.Sequential(\n",
        "                        nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True),  \n",
        "                        nn.MaxPool2d(2,2),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "        )\n",
        "        \n",
        "        # -------------------------------------------------\n",
        "        # Decoder\n",
        "        # -------------------------------------------------\n",
        "        \n",
        "        self.d_layer1 = nn.Sequential(\n",
        "                        nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "                        nn.Conv2d(in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(16),\n",
        "        )        \n",
        "        self.d_layer2 = nn.Sequential(\n",
        "                        nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "                        nn.Conv2d(in_channels=16, out_channels=1, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "                        nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "        \n",
        "        # -------------------------------------------------\n",
        "        # Network\n",
        "        # -------------------------------------------------\n",
        "        self.network = nn.Sequential(\n",
        "                        self.e_layer1,\n",
        "                        self.e_layer2,\n",
        "                        self.d_layer1,\n",
        "                        self.d_layer2,\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "    \n",
        "        out = self.network(x)\n",
        "      \n",
        "        return out\n",
        "\n",
        "    # ======================================================================\n",
        "    # initialize weights\n",
        "    # ======================================================================\n",
        "    def initialize_weight(self):\n",
        "            \n",
        "        for m in self.network.modules():\n",
        "            \n",
        "            if isinstance(m, nn.Conv2d):\n",
        "\n",
        "                nn.init.xavier_uniform_(m.weight) \n",
        "                \n",
        "                if m.bias is not None:\n",
        "\n",
        "                    nn.init.constant_(m.bias, 0.01)\n",
        "                    pass\n",
        "                    \n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                \n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                # nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0.01)\n",
        "                \n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                # nn.init.constant_(m.weight, 1) \n",
        "\n",
        "                if m.bias is not None:\n",
        "                    \n",
        "                    nn.init.constant_(m.bias, 0.01)\n",
        "                    pass"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTptbDGZA9KZ"
      },
      "source": [
        "## Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MgUbMJdA9KZ"
      },
      "source": [
        "model = Network().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum , weight_decay=weight_decay)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAMmqhrUA9KZ"
      },
      "source": [
        "## Compute prediction (denoised image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sE58VDWA9Ka"
      },
      "source": [
        "def compute_prediction(input, model):\n",
        "    \n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    prediction = model(input)\n",
        "    # ==================================================\n",
        "    \n",
        "    return prediction"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4MU2uUwA9Kc"
      },
      "source": [
        "## Compute loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzLZ5_ijB13L"
      },
      "source": [
        "def compute_fidelity(input, prediction):\n",
        "    \n",
        "    mse = nn.MSELoss()\n",
        "    \n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    loss_mse = mse(input,prediction)\n",
        "    # ==================================================\n",
        "    \n",
        "    loss_mse_value = loss_mse.item() \n",
        "    \n",
        "    return loss_mse, loss_mse_value"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J9-SmZeDDHW"
      },
      "source": [
        "def compute_regularization(data, weight):\n",
        "    \n",
        "    bs_img, c_img, h_img, w_img = data.size()\n",
        "   \n",
        "    tv_height = torch.abs(data[:, :, 1:, :] - data[:, :, :- 1, :]).sum()\n",
        "    tv_width  = torch.abs(data[:, :, :, 1:] - data[:, :, :, :-1]).sum()\n",
        "\n",
        "    total_variation = (tv_height + tv_width) / (bs_img * c_img * h_img * w_img)\n",
        "    \n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    loss_regularization = total_variation * weight\n",
        "    # ==================================================\n",
        "    \n",
        "    loss_regularization_value = loss_regularization.item()\n",
        "     \n",
        "    return loss_regularization, loss_regularization_value"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grQ11S2uA9Kc"
      },
      "source": [
        "def compute_loss(input, prediction, weight):\n",
        "\n",
        "    (loss_fidelity, loss_fidelity_value) = compute_fidelity(input, prediction)\n",
        "    (loss_regularization, loss_regularization_value) = compute_regularization(prediction, weight) \n",
        "\n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    loss = loss_fidelity + loss_regularization\n",
        "    # ==================================================\n",
        "    \n",
        "    loss_value = loss.item()\n",
        "    \n",
        "    return loss, loss_value , loss_fidelity_value, loss_regularization_value"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1EWYXG6A9Kc"
      },
      "source": [
        "## Compute PSNR metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtVX7nLCA9Kd"
      },
      "source": [
        "def compute_PSNR(mse):\n",
        "\n",
        "    if (mse==0.):\n",
        "        PSNR=100    \n",
        "    else :\n",
        "        PSNR=10*log10(1.0 / mse)\n",
        "        \n",
        "    return PSNR"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfi3toLTA9Kd"
      },
      "source": [
        "## Variable for the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re9vSZWLA9Kd"
      },
      "source": [
        "loss_fidelity_mean_train       = np.zeros(number_epoch)\n",
        "loss_fidelity_std_train        = np.zeros(number_epoch)\n",
        "loss_regularization_mean_train = np.zeros(number_epoch)\n",
        "loss_regularization_std_train  = np.zeros(number_epoch)\n",
        "loss_mean_train                = np.zeros(number_epoch)\n",
        "loss_std_train                 = np.zeros(number_epoch)\n",
        "PSNR_mean_train                = np.zeros(number_epoch)\n",
        "PSNR_std_train                 = np.zeros(number_epoch)\n",
        "\n",
        "loss_fidelity_mean_test       = np.zeros(number_epoch)\n",
        "loss_fidelity_std_test        = np.zeros(number_epoch)\n",
        "loss_regularization_mean_test = np.zeros(number_epoch)\n",
        "loss_regularization_std_test  = np.zeros(number_epoch)\n",
        "loss_mean_test                = np.zeros(number_epoch)\n",
        "loss_std_test                 = np.zeros(number_epoch)\n",
        "PSNR_mean_test                = np.zeros(number_epoch)\n",
        "PSNR_std_test                 = np.zeros(number_epoch)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2DK1BgcA9Ke"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z6RHIxcA9Ke"
      },
      "source": [
        "def train(model, dataloader):\n",
        "\n",
        "    loss_epoch          = []\n",
        "    loss_fidelity_epoch = []\n",
        "    loss_reg_epoch      = []\n",
        "    psnr_epoch          = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for index_batch, (original, noise) in enumerate(dataloader):\n",
        "\n",
        "        original = original.to(device)\n",
        "        noise    = noise.to(device)\n",
        "        \n",
        "        prediction = compute_prediction(noise, model)\n",
        "        (loss, loss_value, loss_fidelity_value, loss_regularization_value) = compute_loss(noise, prediction, weight_total_variation)\n",
        "        \n",
        "        # ==================================================\n",
        "        # fill up the blank\n",
        "        (mse, mse_value)    = compute_fidelity(prediction,original)\n",
        "        psnr                = compute_PSNR(mse_value)\n",
        "        # ==================================================\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_epoch.append(loss_value)\n",
        "        loss_fidelity_epoch.append(loss_fidelity_value)\n",
        "        loss_reg_epoch.append(loss_regularization_value)\n",
        "        psnr_epoch.append(psnr)\n",
        "\n",
        "    loss_mean_epoch     = np.mean(loss_epoch)\n",
        "    loss_std_epoch      = np.std(loss_epoch)\n",
        "    \n",
        "    loss_fidelity_mean_epoch     = np.mean(loss_fidelity_epoch)\n",
        "    loss_fidelity_std_epoch      = np.std(loss_fidelity_epoch)\n",
        "    \n",
        "    loss_reg_mean_epoch     = np.mean(loss_reg_epoch)\n",
        "    loss_reg_std_epoch      = np.std(loss_reg_epoch)\n",
        "\n",
        "    psnr_mean_epoch = np.mean(psnr_epoch)\n",
        "    psnr_std_epoch  = np.std(psnr_epoch)\n",
        "\n",
        "    loss                       = {'mean' : loss_mean_epoch, 'std' : loss_std_epoch}\n",
        "    loss_fidelity              = {'mean' : loss_fidelity_mean_epoch, 'std' : loss_fidelity_std_epoch}\n",
        "    loss_regularization        = {'mean' : loss_reg_mean_epoch, 'std' : loss_reg_std_epoch}\n",
        "    psnr                       = {'mean' : psnr_mean_epoch, 'std' : psnr_std_epoch}\n",
        "\n",
        "    return (loss, loss_fidelity, loss_regularization, psnr)    \n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z76W6RQWA9Ke"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9FO3jlwA9Ke"
      },
      "source": [
        "def test(model, dataloader):\n",
        "\n",
        "    loss_epoch          = []\n",
        "    loss_fidelity_epoch = []\n",
        "    loss_reg_epoch      = []\n",
        "    psnr_epoch          = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for index_batch, (original, noise) in enumerate(dataloader):\n",
        "\n",
        "        original = original.to(device)\n",
        "        noise    = noise.to(device)\n",
        "\n",
        "        prediction = compute_prediction(noise, model)\n",
        "        (loss, loss_value, loss_fidelity_value, loss_regularization_value) = compute_loss(noise, prediction, weight_total_variation)\n",
        "        \n",
        "        # ==================================================\n",
        "        # fill up the blank\n",
        "        (mse, mse_value)    = compute_fidelity(prediction,original)\n",
        "        psnr                = compute_PSNR(mse_value)\n",
        "        # ==================================================\n",
        "\n",
        "        loss_epoch.append(loss_value)\n",
        "        loss_fidelity_epoch.append(loss_fidelity_value)\n",
        "        loss_reg_epoch.append(loss_regularization_value)\n",
        "        psnr_epoch.append(psnr)\n",
        "\n",
        "    loss_mean_epoch     = np.mean(loss_epoch)\n",
        "    loss_std_epoch      = np.std(loss_epoch)\n",
        "    \n",
        "    loss_fidelity_mean_epoch     = np.mean(loss_fidelity_epoch)\n",
        "    loss_fidelity_std_epoch      = np.std(loss_fidelity_epoch)\n",
        "    \n",
        "    loss_reg_mean_epoch     = np.mean(loss_reg_epoch)\n",
        "    loss_reg_std_epoch      = np.std(loss_reg_epoch)\n",
        "\n",
        "    psnr_mean_epoch = np.mean(psnr_epoch)\n",
        "    psnr_std_epoch  = np.std(psnr_epoch)\n",
        "\n",
        "    loss                       = {'mean' : loss_mean_epoch, 'std' : loss_std_epoch}\n",
        "    loss_fidelity              = {'mean' : loss_fidelity_mean_epoch, 'std' : loss_fidelity_std_epoch}\n",
        "    loss_regularization        = {'mean' : loss_reg_mean_epoch, 'std' : loss_reg_std_epoch}\n",
        "    psnr                       = {'mean' : psnr_mean_epoch, 'std' : psnr_std_epoch}\n",
        "\n",
        "    return (loss, loss_fidelity, loss_regularization, psnr)    \n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl_p_5B2A9Kf"
      },
      "source": [
        "## train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9d855fc37aed4d9b8288aeb8c4e6ddf9",
            "cdf7c3e5de3e472dabec7beaa9b501e4",
            "2276171da6824033ad40a3c6c1ff544b",
            "d0bd2712e3d04115a402cb8e2a2c5cbc",
            "21085e2337114646875c594174cc437e",
            "579b5194bec746839ad337f55e27e70c",
            "4d46aacc34f145f78b7e23349dfea97f",
            "51e4281c2e53430695824cfdc6a2d6de",
            "b2a76c73b768424e91915637d6128e37",
            "05b264e8472d41d584153d03c5493663",
            "3bd67f34f73d4b6c8fb90c8149cae494"
          ]
        },
        "id": "-kpLyy6bA9Kf",
        "outputId": "d661db7c-1978-48c6-bf32-98e2d8381ce9"
      },
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "    (loss_train, loss_fidelity_train, loss_reg_train, psnr_train) = train(model, dataloader_train)\n",
        "\n",
        "    loss_mean_train[i] = loss_train['mean']\n",
        "    loss_std_train[i]  = loss_train['std']\n",
        "    \n",
        "    loss_fidelity_mean_train[i] = loss_fidelity_train['mean']\n",
        "    loss_fidelity_std_train[i]  = loss_fidelity_train['std']\n",
        "    \n",
        "    loss_regularization_mean_train[i] = loss_reg_train['mean']\n",
        "    loss_regularization_std_train[i]  = loss_reg_train['std']\n",
        "\n",
        "    PSNR_mean_train[i]  = psnr_train['mean']\n",
        "    PSNR_std_train[i]   = psnr_train['std']\n",
        "\n",
        "    # ================================================================================\n",
        "    # \n",
        "    # testing\n",
        "    #\n",
        "    # ================================================================================\n",
        "    (loss_test, loss_fidelity_test, loss_reg_test, psnr_test) = test(model, dataloader_test)\n",
        "\n",
        "    loss_mean_test[i] = loss_test['mean']\n",
        "    loss_std_test[i]  = loss_test['std']\n",
        "\n",
        "    loss_fidelity_mean_test[i] = loss_fidelity_test['mean']\n",
        "    loss_fidelity_std_test[i]  = loss_fidelity_test['std']\n",
        "    \n",
        "    loss_regularization_mean_test[i] = loss_reg_test['mean']\n",
        "    loss_regularization_std_test[i]  = loss_reg_test['std']\n",
        "\n",
        "    PSNR_mean_test[i]  = psnr_test['mean']\n",
        "    PSNR_std_test[i]   = psnr_test['std']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d855fc37aed4d9b8288aeb8c4e6ddf9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxek0ypkA9Kf"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4N32do7A9Kg"
      },
      "source": [
        "# functions for visualizing the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY1ul6ttA9Kg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgD-FF4MA9Kg"
      },
      "source": [
        "## Plot functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7SzyQnaA9Kg"
      },
      "source": [
        "def plot_data_grid(data, index_data, nRow, nCol):\n",
        "    \n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * 3, nRow * 3))\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            index   = index_data[k]\n",
        "\n",
        "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVYA6nBGA9Kh"
      },
      "source": [
        "def plot_data_tensor_grid(data, index_data, nRow, nCol):\n",
        "    \n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * 3, nRow * 3))\n",
        "\n",
        "    data = data.detach().cpu().squeeze(axis=1)\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            index   = index_data[k]\n",
        "\n",
        "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r06Lf6UNA9Kh"
      },
      "source": [
        "def plot_curve_error(data_mean, data_std, x_label, y_label, title):\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    alpha = 0.3\n",
        "    \n",
        "    plt.plot(range(len(data_mean)), data_mean, '-', color = 'red')\n",
        "    plt.fill_between(range(len(data_mean)), data_mean - data_std, data_mean + data_std, facecolor = 'blue', alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBmjFM9tA9Kh"
      },
      "source": [
        "def print_curve(data, index):\n",
        "    \n",
        "    for i in range(len(index)):\n",
        "\n",
        "        idx = index[i]\n",
        "        val = data[idx]\n",
        "\n",
        "        print('index = %2d, value = %12.10f' % (idx, val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5_ePFORA9Ki"
      },
      "source": [
        "def get_data_last(data, index_start):\n",
        "\n",
        "    data_last = data[index_start:]\n",
        "\n",
        "    return data_last"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFNAv5nnA9Ki"
      },
      "source": [
        "def get_max_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.max()\n",
        "\n",
        "    return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0FhjnneA9Ki"
      },
      "source": [
        "def get_min_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.min()\n",
        "\n",
        "    return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR2U5WquA9Kj"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnBT9fWXA9Kj"
      },
      "source": [
        "# functions for presenting the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak9mEQ11A9Kj"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mSysHDcA9Kk"
      },
      "source": [
        "def function_result_01():\n",
        "\n",
        "    print('[plot examples of the training images]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 5 \n",
        "    nCol = 4\n",
        "    index_data  = np.arange(0, nRow * nCol)\n",
        "    image_train = dataset_train.noise[index_data]\n",
        "\n",
        "    plot_data_grid(image_train, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG5Dv-BtA9Kk"
      },
      "source": [
        "def function_result_02():\n",
        "\n",
        "    print('[plot examples of the training denoising results]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 5\n",
        "    nCol = 4\n",
        "    index_data          = np.arange(0, nRow * nCol)\n",
        "    image_train         = torch.FloatTensor(dataset_train.noise[index_data]).unsqueeze(dim=1).to(device)\n",
        "    prediction_train    = compute_prediction(image_train,model)\n",
        "    \n",
        "    plot_data_tensor_grid(prediction_train, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AOFrS4wA9Kk"
      },
      "source": [
        "def function_result_03():\n",
        "\n",
        "    print('[plot examples of the testing images]')\n",
        "    print('') \n",
        "    \n",
        "    nRow = 5\n",
        "    nCol = 4\n",
        "    index_data = np.arange(0, nRow * nCol)\n",
        "    image_test = dataset_test.noise[index_data]\n",
        "\n",
        "    plot_data_grid(image_test, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2jAuO-HA9Kl"
      },
      "source": [
        "def function_result_04():\n",
        "\n",
        "    print('[plot examples of the testing denoising results]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 5\n",
        "    nCol = 4\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    image_test      = torch.FloatTensor(dataset_test.noise[index_data]).unsqueeze(dim=1).to(device)\n",
        "    prediction_test = compute_prediction(image_test,model)\n",
        "\n",
        "    plot_data_tensor_grid(prediction_test, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q_8MOVKA9Kl"
      },
      "source": [
        "def function_result_05():\n",
        "\n",
        "    print('[plot the training loss]')\n",
        "    print('') \n",
        "\n",
        "    plot_curve_error(loss_mean_train, loss_std_train, 'epoch', 'loss', 'training loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4aH0BefQhUi"
      },
      "source": [
        "def function_result_06():\n",
        "\n",
        "    print('[plot the training fidelity loss]')\n",
        "    print('') \n",
        "\n",
        "    plot_curve_error(loss_fidelity_mean_train, loss_fidelity_std_train, 'epoch', 'loss', 'training loss (fidelity)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHnNBNcQw9a"
      },
      "source": [
        "def function_result_07():\n",
        "\n",
        "    print('[plot the training regularization loss]')\n",
        "    print('') \n",
        "\n",
        "    plot_curve_error(loss_regularization_mean_train, loss_regularization_std_train, 'epoch', 'loss', 'training loss (regularization)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvRfH6ejA9Kl"
      },
      "source": [
        "def function_result_08():\n",
        "\n",
        "    print('[plot the training PSNR]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(PSNR_mean_train, PSNR_std_train, 'epoch', 'PSNR', 'training PSNR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08ILy67PA9Km"
      },
      "source": [
        "def function_result_09():\n",
        "    \n",
        "    print('[plot the testing loss]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(loss_mean_test, loss_std_test, 'epoch', 'loss', 'testing loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzRElUYcREsr"
      },
      "source": [
        "def function_result_10():\n",
        "    \n",
        "    print('[plot the testing fidelity loss]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(loss_fidelity_mean_test, loss_fidelity_std_test, 'epoch', 'loss', 'testing loss (fidelity)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp0_wwYyRM8f"
      },
      "source": [
        "def function_result_11():\n",
        "    \n",
        "    print('[plot the testing regularization loss]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(loss_regularization_mean_test, loss_regularization_std_test, 'epoch', 'loss', 'testing loss (regularization)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHDnt4ndA9Km"
      },
      "source": [
        "def function_result_12():\n",
        "    \n",
        "    print('[plot the testing PSNR]') \n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(PSNR_mean_test, PSNR_std_test, 'epoch', 'PSNR', 'testing PSNR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HlkP764A9Km"
      },
      "source": [
        "def function_result_13():\n",
        "    \n",
        "    print('[print the training loss (mean) at the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    data_last = get_data_last(loss_mean_train, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JAxHIggA9Kn"
      },
      "source": [
        "def function_result_14():\n",
        "    \n",
        "    print('[print the training PSNR (mean) at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last = get_data_last(PSNR_mean_train, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHP4nAgxA9Kn"
      },
      "source": [
        "def function_result_15():\n",
        "    \n",
        "    print('[print the testing loss (mean) at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last = get_data_last(loss_mean_test, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lslaY-A1A9Ko"
      },
      "source": [
        "def function_result_16():\n",
        "    \n",
        "    print('[print the testing PSNR (mean) at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last = get_data_last(PSNR_mean_test, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_xYLoXkA9Ko"
      },
      "source": [
        "def function_result_17():\n",
        "    \n",
        "    print('[print the best training PSNR (mean) within the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    value = get_max_last_range(PSNR_mean_train, -10)\n",
        "    print('best training PSNR = %12.10f' % (value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d0Zf7lsA9Ko"
      },
      "source": [
        "def function_result_18():\n",
        "    \n",
        "    print('[print the best testing PSNR (mean) within the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    value = get_max_last_range(PSNR_mean_test, -10)\n",
        "    print('best testing PSNR = %12.10f' % (value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-Nw6A2jA9Kp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa6-Ktz8A9Kp"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHREmjnvA9Kp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cGBA-ccA9Kp"
      },
      "source": [
        "number_result = 18\n",
        "\n",
        "for i in range(number_result):\n",
        "\n",
        "    title           = '# RESULT # {:02d}'.format(i+1) \n",
        "    name_function   = 'function_result_{:02d}()'.format(i+1)\n",
        "\n",
        "    print('') \n",
        "    print('################################################################################')\n",
        "    print('#') \n",
        "    print(title)\n",
        "    print('#') \n",
        "    print('################################################################################')\n",
        "    print('') \n",
        "\n",
        "    eval(name_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2JnRWygXHL4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}